When using this tool, always use the `jq_filter` parameter to reduce the response size and improve performance. Only omit if you're sure you don't need the data. Create a prediction using an [official model](https://replicate.com/changelog/2025-01-29-official-models). If you're _not_ running an official model, use the [`predictions.create`](#predictions.create) operation instead. Example cURL request: ```console curl -s -X POST -H 'Prefer: wait' \ -d '{"input": {"prompt": "Write a short poem about the weather."}}' \ -H "Authorization: Bearer $REPLICATE_API_TOKEN" \ -H 'Content-Type: application/json' \ https://api.replicate.com/v1/models/meta/meta-llama-3-70b-instruct/predictions ``` The request will wait up to 60 seconds for the model to run. If this time is exceeded the prediction will be returned in a `"starting"` state and need to be retrieved using the `predictions.get` endpiont. For a complete overview of the `deployments.predictions.create` API check out our documentation on [creating a prediction](https://replicate.com/docs/topics/predictions/create-a-prediction) which covers a variety of use cases. # Response Schema ```json { $ref: '#/$defs/prediction', $defs: { prediction: { type: 'object', properties: { id: { type: 'string' }, created_at: { type: 'string', description: 'The time that the prediction was created', format: 'date-time' }, data_removed: { type: 'boolean', description: 'Whether the prediction output has been deleted' }, error: { type: 'string', description: 'An error string if the model status is `"failed"`' }, input: { type: 'object', description: 'The prediction input', additionalProperties: true }, model: { type: 'string', description: 'The name of the model that created the prediction' }, output: { $ref: '#/$defs/prediction_output' }, status: { type: 'string', enum: [ 'starting', 'processing', 'succeeded', 'failed', 'canceled' ] }, urls: { type: 'object', description: 'URLs for working with the prediction', properties: { cancel: { type: 'string', description: 'Cancel the prediction via API' }, get: { type: 'string', description: 'Retrieve the latest state of the prediction via API' }, web: { type: 'string', description: 'View the prediction in a browser' }, stream: { type: 'string', description: 'An event source to stream the output of the prediction via API' } }, required: [ 'cancel', 'get', 'web' ] }, version: { anyOf: [ { type: 'string', description: 'The ID of the model version that created the prediction' }, { type: 'string', description: 'The model does not support versions, used by official models.', enum: [ 'hidden' ] } ], description: 'The ID of the model version that created the prediction' }, completed_at: { type: 'string', description: 'The time that the model completed the prediction and all outputs were uploaded', format: 'date-time' }, deployment: { type: 'string', description: 'The name of the deployment that created the prediction' }, logs: { type: 'string', description: 'The log output from the model' }, metrics: { type: 'object', description: 'Additional metrics associated with the prediction', additionalProperties: true }, started_at: { type: 'string', description: 'The time that the model began the prediction', format: 'date-time' } }, required: [ 'id', 'created_at', 'data_removed', 'error', 'input', 'model', 'output', 'status', 'urls', 'version' ] }, prediction_output: { type: 'object', description: 'The prediction output, which can be any JSON-serializable value, depending on the model', additionalProperties: true } } } ```

